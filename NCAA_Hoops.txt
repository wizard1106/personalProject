# -*- coding: utf-8 -*-
"""
@author: Chad.Birger
"""

import pandas as pd
import datetime as dt
import requests
import time

def daterange(start_date, end_date):
    for n in range(int((end_date - start_date).days)):
        yield start_date + dt.timedelta(n)

season_start = dt.date(2023, 11, 6)
today = dt.date.today()
game_id = []
for single_date in daterange(season_start, today):
    date_val = single_date.strftime("%Y/%m/%d")
    mm = "{:02d}".format(single_date.month)
    dd = "{:02d}".format(single_date.day)
    YYYY = single_date.year
    #URL = "https://www.ncaa.com/scoreboard/basketball-men/d1/" + str(date_val) + "/all-conf"
    URL = "https://stats.ncaa.org/season_divisions/18221/livestream_scoreboards?utf8=%E2%9C%93&season_division_id=&game_date="+ str(mm) + '%2F' + str(dd) + '%2F'+ str(YYYY) + '&conference_id=0&tournament_id=&commit=Submit'
    headers = {"User-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.80 Safari/537.36"}
    page = requests.get(URL, headers=headers)
    games_today = []
    cur = 0
    today_schedule = page.text
    while cur >= 0:
        today_schedule = today_schedule[cur:]
        g = today_schedule.find('<tr id="contest_')
        if g < 0:
            break
        games_today.append(today_schedule[g+16: g+23])
        cur = g+24
    game_id.append(games_today)
### Remove duplicate game_id values
gameId = []    
for row in game_id:
    gameId.append(set(row))

game_ids = []
for row in gameId:
    game_ids.append(list(row))
    
#The following is an example to pull one-game worth of data: 
game = game_ids[69][4]
url = 'https://stats.ncaa.org/contests/' +str(game)+'/box_score' 
df_box_score = pd.read_html(url)
time.sleep(1)
headers = {"User-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.80 Safari/537.36"}
page = requests.get(url, headers=headers)
game_info = page.text
g = game_info.find('<a href="/game/play_by_play/')
if g < 0:
    print("not found")
game2 = game_info[g+28: g+35]

url2 = 'https://stats.ncaa.org/game/play_by_play/' +str(game2)
df_pxp = pd.read_html(url2)
time.sleep(1)
url3 =  'https://stats.ncaa.org/game/period_stats/' +str(game2)
df_period_stats = pd.read_html(url3)
time.sleep(1)


game_list=[]
game_list2= []
game_results_box_score = []
game_results_pxp = []
game_results_period_stats = []
no_games = []
for row in game_ids:
    for gameId in row:
        try:
            url =  'https://stats.ncaa.org/contests/' + str(gameId) + '/box_score'
            #url = 'ncaa.com/game/' + str(gameId)
            df_box_score = pd.read_html(url)
            time.sleep(3)
            headers = {"User-agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.80 Safari/537.36"}
            page = requests.get(url, headers=headers)
            game_info = page.text
            g = game_info.find('<a href="/game/play_by_play/')
            if g < 0:
                print("not found")
            game2 = game_info[g+28: g+35]
            url2 = 'https://stats.ncaa.org/game/play-by-play/' +str(game2)
            df_pxp = pd.read_html(url2)
            time.sleep(3)
            url3 =  'https://stats.ncaa.org/game/period_stats/' +str(game2)
            df_period_stats = pd.read_html(url3)
            time.sleept(3)
            game_results_box_score.append(df_box_score)
            game_results_pxp.append(df_pxp)
            game_results_period_stats.append(df_period_stats)
            game_list.append(gameId)
        except ValueError:
            no_games.append(gameId)
            pass

